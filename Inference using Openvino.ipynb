{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-07 04:36:59.250728: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-07 04:37:04.021778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 357 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:1a:00.0, compute capability: 7.0\n",
      "2022-04-07 04:37:04.023074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14478 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:1b:00.0, compute capability: 7.0\n",
      "2022-04-07 04:37:04.024337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 14406 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3d:00.0, compute capability: 7.0\n",
      "2022-04-07 04:37:04.025547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 12289 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3e:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('Task1Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: mo_tf.py: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!mo_tf.py --input_model model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/dwip.dalal/Image classifcation/model\n",
      "\t- Path for generated IR: \t/home/dwip.dalal/Image classifcation/.\n",
      "\t- IR output name: \tmodel\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Source layout: \tNot specified\n",
      "\t- Target layout: \tNot specified\n",
      "\t- Layout: \tNot specified\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- User transformations: \tNot specified\n",
      "\t- Reverse input channels: \tFalse\n",
      "\t- Enable IR generation for fixed input shape: \tFalse\n",
      "\t- Use the transformations config file: \tNone\n",
      "Advanced parameters:\n",
      "\t- Force the usage of legacy Frontend of Model Optimizer for model conversion into IR: \tFalse\n",
      "\t- Force the usage of new Frontend of Model Optimizer for model conversion into IR: \tFalse\n",
      "TensorFlow specific parameters:\n",
      "\t- Input model in text protobuf format: \tFalse\n",
      "\t- Path to model dump for TensorBoard: \tNone\n",
      "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
      "\t- Update the configuration file with input/output node names: \tNone\n",
      "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
      "\t- Use the config file: \tNone\n",
      "OpenVINO runtime found in: \t/home/dwip.dalal/anaconda3/envs/py37/lib/python3.7/openvino\n",
      "OpenVINO runtime version: \t2022.1.0-7019-cdb9bec7210-releases/2022/1\n",
      "Model Optimizer version: \t2022.1.0-7009-19bdd019745-refs/pull/1012/head\n",
      "[ WARNING ] Model Optimizer and OpenVINO runtime versions do no match.\n",
      "[ WARNING ] Consider building the OpenVINO Python API from sources or reinstall OpenVINO (TM) toolkit using \"pip install openvino==2022.1\"\n",
      "[ FRAMEWORK ERROR ]  Cannot load input model: TensorFlow cannot read the model file: \"/home/dwip.dalal/Image classifcation/model\" is incorrect TensorFlow model file. \n",
      "The file should contain one of the following TensorFlow graphs:\n",
      "1. frozen graph in text or binary format\n",
      "2. inference graph for freezing with checkpoint (--input_checkpoint) in text or binary format\n",
      "3. meta graph\n",
      "\n",
      "Make sure that --input_model_is_text is provided for a model in text format. By default, a model is interpreted in binary format. Framework error details: [Errno 21] Is a directory: '/home/dwip.dalal/Image classifcation/model'. \n",
      " For more information please refer to Model Optimizer FAQ, question #43. (https://docs.openvino.ai/latest/openvino_docs_MO_DG_prepare_model_Model_Optimizer_FAQ.html?question=43#question-43)\n"
     ]
    }
   ],
   "source": [
    "!mo --input_model model --framework tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37]",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
